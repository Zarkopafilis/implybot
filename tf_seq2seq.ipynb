{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import string\n",
    "import math\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import fasttext as ft\n",
    "import fasttext.util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')], True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU'), tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Nigger in the house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Nigger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>\"Yes\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>I have a hard on right now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>same tbh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>im actually jerking off rn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>I'm fapping to cosplaying kids</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>con season is best season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             chat\n",
       "0             Nigger in the house\n",
       "1                          Nigger\n",
       "2                           \"Yes\"\n",
       "3      I have a hard on right now\n",
       "4                        same tbh\n",
       "5      im actually jerking off rn\n",
       "6  I'm fapping to cosplaying kids\n",
       "7                            same\n",
       "8       con season is best season\n",
       "9                            true"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our dataset is around ~15mb\n",
    "df = pd.read_csv('old_general.csv', header=None, usecols=[2], names=['chat'])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>nigger in the house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>nigger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>i have a hard on right now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>same tbh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>im actually jerking off rn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>im fapping to cosplaying kids</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>con season is best season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            chat\n",
       "0            nigger in the house\n",
       "1                         nigger\n",
       "2                            yes\n",
       "3     i have a hard on right now\n",
       "4                       same tbh\n",
       "5     im actually jerking off rn\n",
       "6  im fapping to cosplaying kids\n",
       "7                           same\n",
       "8      con season is best season\n",
       "9                           true"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UNK = 'xxunk'\n",
    "# OOV included in encoder\n",
    "\n",
    "def raw_text_preprocess(x):\n",
    "    return x.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "df['chat'] = df['chat'].apply(raw_text_preprocess)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{70: 7.0, 80: 9.0, 90: 12.0, 95: 16.0, 97: 19.0, 99: 28.0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tkn_len'] = df['chat'].apply(lambda x: len(x.split(' ')))\n",
    "\n",
    "_p = {i: np.percentile([l for l in df['tkn_len'].values], i) for i in [70, 80, 90, 95, 97, 99]}\n",
    "\n",
    "_p # {70: 7.0, 80: 9.0, 90: 12.0, 95: 16.0, 97: 19.0, 99: 28.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chat</th>\n",
       "      <th>tkn_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>xxbos nigger in the house xxeos</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>xxbos nigger xxeos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>xxbos yes xxeos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>xxbos i have a hard on right now xxeos</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>xxbos same tbh xxeos</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>xxbos im actually jerking off rn xxeos</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>xxbos im fapping to cosplaying kids xxeos</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>xxbos same xxeos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>xxbos con season is best season xxeos</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>xxbos true xxeos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        chat  tkn_len\n",
       "0            xxbos nigger in the house xxeos        4\n",
       "1                         xxbos nigger xxeos        1\n",
       "2                            xxbos yes xxeos        1\n",
       "3     xxbos i have a hard on right now xxeos        7\n",
       "4                       xxbos same tbh xxeos        2\n",
       "5     xxbos im actually jerking off rn xxeos        5\n",
       "6  xxbos im fapping to cosplaying kids xxeos        5\n",
       "7                           xxbos same xxeos        1\n",
       "8      xxbos con season is best season xxeos        5\n",
       "9                           xxbos true xxeos        1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_TOKENS = 20\n",
    "\n",
    "BOS = 'xxbos'\n",
    "EOS = 'xxeos'\n",
    "\n",
    "def add_utility_tokens(r):\n",
    "    content = r['chat']\n",
    "\n",
    "    return f'{BOS} {content} {EOS}'\n",
    "\n",
    "df['chat'] = df.apply(add_utility_tokens, axis=1)\n",
    "\n",
    "MAX_TOKENS += 2\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['chat_shift'] = df['chat'].shift(-1)\n",
    "df.drop(df.tail(1).index, inplace=True) # drop last row for NaN due to shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1427633e913b45bdac2698e0c87baaa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=183090.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19923"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize and build vocab\n",
    "tokenizer = tfds.features.text.Tokenizer()\n",
    "\n",
    "vocab_counter = Counter()\n",
    "\n",
    "for _, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "  xb = row['chat']\n",
    "  xb_tokens = tokenizer.tokenize(xb)\n",
    "  vocab_counter.update(xb_tokens)\n",
    "\n",
    "# keep only words that appear more than OCCURENCES_TRESHOLD\n",
    "OCCURENCES_TRESHOLD = 2\n",
    "vocabulary_set = set(el for el in vocab_counter.elements() if vocab_counter[el] >= OCCURENCES_TRESHOLD)\n",
    "\n",
    "vocabulary_set.update([BOS, EOS, UNK])\n",
    "   \n",
    "vocab_size = len(vocabulary_set)\n",
    "\n",
    "encoder = tfds.features.text.TokenTextEncoder(vocabulary_set) \n",
    "\n",
    "vocab_size += 1 # OOV word included in encoder\n",
    "\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load fasttext model and build embeddings layer\n",
    "# ft.util.download_model('en', if_exists='ignore')\n",
    "en_vecs = ft.load_model('./cc.en.300.bin')\n",
    "en_vecs.get_dimension() # 300\n",
    "\n",
    "# Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
    "# you can safely ignore this warning, it's for other model types and (possibly) deprecation warning for other versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, 300))\n",
    "\n",
    "for word in vocabulary_set:\n",
    "    i = encoder.encode(word)\n",
    "    embedding_matrix[i] = en_vecs.get_word_vector(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# release 8gb of memory by unloading the fasttext model\n",
    "del en_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODER_INPUT_NAME = 'encoder_input'\n",
    "DECODER_INPUT_NAME = 'decoder_input'\n",
    "DECODER_OUTPUT_NAME = 'decoder_output'\n",
    "\n",
    "# What if I don't want to use teacher forcing for training?\n",
    "# https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html\n",
    "\n",
    "# you could make this lazy-generator wise too\n",
    "#for _, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "def keras_data_generator(dataframe):\n",
    "    while True:\n",
    "        for _, row in dataframe.iterrows():\n",
    "            ch = row['chat']\n",
    "            ch_shift = row['chat_shift']\n",
    "\n",
    "            xb, yb = encoder.encode(ch), encoder.encode(ch_shift)\n",
    "            if len(xb) >= MAX_TOKENS or len(yb) >= MAX_TOKENS:\n",
    "                continue\n",
    "\n",
    "            pad_len = MAX_TOKENS - len(xb)\n",
    "            pad_xb = [[0, pad_len]]\n",
    "            xb_padded = tf.pad(xb, pad_xb)\n",
    "\n",
    "            # [enc_input, dec_input], dec_output\n",
    "            for i in range(1, len(yb)):\n",
    "                pad_len = MAX_TOKENS-i\n",
    "                if pad_len < 0:\n",
    "                    print(f'{ch} - {ch_shift} - yb => {pad_len} i = {i}')\n",
    "\n",
    "                dec_in = yb[0:i]\n",
    "                dec_in = tf.pad(yb[0:i], [[0, pad_len]])\n",
    "\n",
    "                tf.stack([xb_padded, dec_in]), yb[i]\n",
    "\n",
    "                # yields\n",
    "                yield {ENCODER_INPUT_NAME: xb_padded, DECODER_INPUT_NAME: dec_in}, {DECODER_OUTPUT_NAME: np.array([yb[i]])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'encoder_input': <tf.Tensor: shape=(22,), dtype=int32, numpy=\n",
       "  array([ 5517,  3291,  8744,  4850, 15186, 18256,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0])>,\n",
       "  'decoder_input': <tf.Tensor: shape=(22,), dtype=int32, numpy=\n",
       "  array([5517,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0])>},\n",
       " {'decoder_output': array([3291])})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(keras_data_generator(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input (InputLayer)      [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_embedding (Embedding)   (None, None, 300)    5976900     encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_embedding (Embedding)   (None, None, 300)    5976900     decoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "encoder_lstm (LSTM)             [(None, 128), (None, 219648      encoder_embedding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)             (None, 128)          219648      decoder_embedding[0][0]          \n",
      "                                                                 encoder_lstm[0][1]               \n",
      "                                                                 encoder_lstm[0][2]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output (Dense)          (None, 19923)        2570067     decoder_lstm[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 14,963,163\n",
      "Trainable params: 14,963,163\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "\n",
    "# https://keras.io/examples/lstm_seq2seq/\n",
    "\n",
    "# this one messes with layer names and appends :X numbers\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "latent_dim = 128\n",
    "\n",
    "input_tensor_type = tf.int64\n",
    "\n",
    "encoder_embedding = tf.keras.layers.Embedding(vocab_size, 300, weights=[embedding_matrix], name='encoder_embedding')\n",
    "decoder_embedding = tf.keras.layers.Embedding(vocab_size, 300, weights=[embedding_matrix], name='decoder_embedding')\n",
    "\n",
    "enc_dec_input_shape = (None,)\n",
    "\n",
    "# input is (tokens, vocab size)\n",
    "encoder_input = Input(shape=enc_dec_input_shape, dtype=input_tensor_type, name=ENCODER_INPUT_NAME)\n",
    "\n",
    "# embedding dim is 300 from the fasttext model\n",
    "encoder_embedding = encoder_embedding(encoder_input) # None, MAX_TOKENS, 300\n",
    "\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True, name='encoder_lstm')\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# # same logic as model_input\n",
    "decoder_input = Input(shape=enc_dec_input_shape, dtype=input_tensor_type, name=DECODER_INPUT_NAME)\n",
    "decoder_embedding = decoder_embedding(decoder_input)\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=False, name='decoder_lstm')(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_output = Dense(vocab_size, activation='softmax', name=DECODER_OUTPUT_NAME)(decoder_lstm)\n",
    "\n",
    "model = Model([encoder_input, decoder_input], decoder_output)\n",
    "\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "model.fit(keras_data_generator(df), epochs=5, steps_per_epoch=df.shape[0]//BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[6., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define wiring of sampling models to get some faster inference\n",
    "\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    enc_input_seq = encoder.encode(input_seq)\n",
    "    \n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Batch size is 1 this is why there is an extra sequence\n",
    "    target_seq = np.zeros((1, 1, MAX_TOKENS))\n",
    "    \n",
    "    # sampling recurrent loop\n",
    "\n",
    "    i = 0\n",
    "    target_seq[0, 0, i] = encoder.encode(BOS)\n",
    "    decoded_sentence = ''\n",
    "    while True:\n",
    "        i += 1\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # argmax the output to get next token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word = encoder.decode[sampled_token_index]\n",
    "\n",
    "        decoded_sentence += sampled_word\n",
    "\n",
    "        # if max length or EOS, stop\n",
    "        if (sampled_char == EOS or\n",
    "           len(decoded_sentence) > MAX_TOKENS):\n",
    "            break\n",
    "\n",
    "        # update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, i] = sampled_token_index\n",
    "\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize some results from test data\n",
    "\n",
    "test_data = ['Whatsup bot?', 'marios is good', 'can i get admin pretty pls']\n",
    "\n",
    "for raw_text in test_data:\n",
    "    input_text = raw_text_preprocess(raw_text)\n",
    "\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_text)\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep learning\n",
    "encoder_model.save('encoder_model', save_format='tf')\n",
    "decoder_model.save('encoder_model', save_format='tf')\n",
    "\n",
    "# vocabulary maps\n",
    "encoder.save_to_file('text.encoder')"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
