{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import string\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import fasttext as ft\n",
    "import fasttext.util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')], True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU'), tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Nigger in the house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Nigger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>\"Yes\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>I have a hard on right now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>same tbh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>im actually jerking off rn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>I'm fapping to cosplaying kids</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>con season is best season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             chat\n",
       "0             Nigger in the house\n",
       "1                          Nigger\n",
       "2                           \"Yes\"\n",
       "3      I have a hard on right now\n",
       "4                        same tbh\n",
       "5      im actually jerking off rn\n",
       "6  I'm fapping to cosplaying kids\n",
       "7                            same\n",
       "8       con season is best season\n",
       "9                            true"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our dataset is around ~15mb\n",
    "df = pd.read_csv('old_general.csv', header=None, usecols=[2], names=['chat'])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>nigger in the house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>nigger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>i have a hard on right now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>same tbh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>im actually jerking off rn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>im fapping to cosplaying kids</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>con season is best season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            chat\n",
       "0            nigger in the house\n",
       "1                         nigger\n",
       "2                            yes\n",
       "3     i have a hard on right now\n",
       "4                       same tbh\n",
       "5     im actually jerking off rn\n",
       "6  im fapping to cosplaying kids\n",
       "7                           same\n",
       "8      con season is best season\n",
       "9                           true"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UNK = 'xxunk'\n",
    "# OOV included in encoder\n",
    "\n",
    "def raw_text_preprocess(x):\n",
    "    return x.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "df['chat'] = df['chat'].apply(raw_text_preprocess)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{70: 7.0, 80: 9.0, 90: 12.0, 95: 16.0, 97: 19.0, 99: 28.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tkn_len'] = df['chat'].apply(lambda x: len(x.split(' ')))\n",
    "\n",
    "_p = {i: np.percentile([l for l in df['tkn_len'].values], i) for i in [70, 80, 90, 95, 97, 99]}\n",
    "\n",
    "_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chat</th>\n",
       "      <th>tkn_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>xxbos nigger in the house xxeos</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>xxbos nigger xxeos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>xxbos yes xxeos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>xxbos i have a hard on right now xxeos</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>xxbos same tbh xxeos</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>xxbos im actually jerking off rn xxeos</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>xxbos im fapping to cosplaying kids xxeos</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>xxbos same xxeos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>xxbos con season is best season xxeos</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>xxbos true xxeos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        chat  tkn_len\n",
       "0            xxbos nigger in the house xxeos        4\n",
       "1                         xxbos nigger xxeos        1\n",
       "2                            xxbos yes xxeos        1\n",
       "3     xxbos i have a hard on right now xxeos        7\n",
       "4                       xxbos same tbh xxeos        2\n",
       "5     xxbos im actually jerking off rn xxeos        5\n",
       "6  xxbos im fapping to cosplaying kids xxeos        5\n",
       "7                           xxbos same xxeos        1\n",
       "8      xxbos con season is best season xxeos        5\n",
       "9                           xxbos true xxeos        1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_TOKENS = 20\n",
    "\n",
    "df = df[df['tkn_len'] <= MAX_TOKENS]\n",
    "\n",
    "BOS = 'xxbos'\n",
    "EOS = 'xxeos'\n",
    "\n",
    "def add_utility_tokens(r):\n",
    "    content = r['chat']\n",
    "\n",
    "    return f'{BOS} {content} {EOS}'\n",
    "\n",
    "df['chat'] = df.apply(add_utility_tokens, axis=1)\n",
    "\n",
    "MAX_TOKENS += 2\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# push to tensorflow\n",
    "df['chat_shift'] = df['chat'].shift(-1)\n",
    "df.drop(df.tail(1).index, inplace=True) # drop last row for NaN due to shift\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((df['chat'].values, df['chat_shift'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43605"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize and build vocab\n",
    "tokenizer = tfds.features.text.Tokenizer()\n",
    "\n",
    "vocabulary_set = set()\n",
    "vocabulary_set.update([BOS, EOS, UNK])\n",
    "\n",
    "for xb, yb in dataset:\n",
    "  xb_tokens = tokenizer.tokenize(xb.numpy())\n",
    "  vocabulary_set.update(xb_tokens)\n",
    "\n",
    "  yb_tokens = tokenizer.tokenize(yb.numpy())\n",
    "  vocabulary_set.update(yb_tokens)\n",
    "\n",
    "vocab_size = len(vocabulary_set)\n",
    "vocab_size += 1 # for padding introduced dataset.padded_batch (as 0.0f)\n",
    "\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'xxbos im fapping to cosplaying kids xxeos'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataset.shuffle(10)))[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6,), dtype=int64, numpy=array([35301,   579, 36036,  9786, 16519, 31726], dtype=int64)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = tfds.features.text.TokenTextEncoder(vocabulary_set)\n",
    "\n",
    "# collate_fn (for the fastai users)\n",
    "def encode(xb, yb):\n",
    "  enc_x, enc_y = encoder.encode(xb.numpy()), encoder.encode(yb.numpy())\n",
    "  return enc_x, enc_y\n",
    "\n",
    "def encode_map_fn(xb, yb):\n",
    "  enc_xb, enc_yb = tf.py_function(encode, \n",
    "                                       inp=[xb, yb], \n",
    "                                       Tout=(tf.int64, tf.int64))\n",
    "  return enc_xb, enc_yb\n",
    "\n",
    "dataset = dataset.map(encode_map_fn)\n",
    "next(iter(dataset))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoded_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-041a634e89f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoded_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mskip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTAKE_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBUFFER_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadded_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'encoded_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "BUFFER_SIZE = 1024\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "# it's a small dataset in memory, we don't need\n",
    "# prefetch or caching\n",
    "\n",
    "# https://www.tensorflow.org/guide/data_performance\n",
    "train_data = dataset.batch(BATCH_SIZE)\n",
    "                    .map(encode_map_fn,\n",
    "                        num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    "                        )\n",
    "                    .unbatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_dataset_generator(ds, epochs=10):\n",
    "    _ds = ds.unbatch().repeat(epochs)\n",
    "    for xb, yb in _ds:\n",
    "        pad_xb = [[0, MAX_TOKENS-len(xb)]]\n",
    "        xb_padded = tf.pad(xb, pad_xb, mode='CONSTANT')\n",
    "        # [enc_input, dec_input, ]\n",
    "        for i in range(1, len(yb)):\n",
    "            yield [xb, tf.pad(yb[0:i], [[0, MAX_TOKENS-i]], mode='CONSTANT')], yb[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load fasttext model and build embeddings layer\n",
    "# ft.util.download_model('en', if_exists='ignore')\n",
    "en_vecs = ft.load_model('./cc.en.300.bin')\n",
    "en_vecs.get_dimension() # 300\n",
    "\n",
    "# Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
    "# you can safely ignore this warning, it's for other model types and (possibly) deprecation warning for other versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.embeddings.Embedding at 0x223f6a0e948>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, 300))\n",
    "\n",
    "for word in vocabulary_set:\n",
    "    i = encoder.encode(word)\n",
    "    embedding_matrix[i] = en_vecs.get_word_vector(word)\n",
    "\n",
    "embedding_layer = tf.keras.layers.Embedding(vocab_size, 300, weights=[embedding_matrix], name='embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_input (InputLayer)      [(None, 22)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_input (InputLayer)      [(None, 22)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           multiple             13081500    encoder_input[0][0]              \n",
      "                                                                 decoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "encoder_lstm (LSTM)             [(None, 128), (None, 219648      embedding[9][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)             [(None, 22, 128), (N 219648      embedding[10][0]                 \n",
      "                                                                 encoder_lstm[0][1]               \n",
      "                                                                 encoder_lstm[0][2]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_dense (Dense)           (None, 22, 959310)   123750990   decoder_lstm[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 137,271,786\n",
      "Trainable params: 137,271,786\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "\n",
    "# https://keras.io/examples/lstm_seq2seq/\n",
    "\n",
    "latent_dim = 128\n",
    "\n",
    "# input is (tokens, vocab size)\n",
    "encoder_input = Input(shape=(MAX_TOKENS), name='encoder_input')\n",
    "\n",
    "# embedding dim is 300 from the fasttext model\n",
    "encoder_embedding = embedding_layer(encoder_input) # None, MAX_TOKENS, 300\n",
    "\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True, name='encoder_lstm')\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# # same logic as model_input\n",
    "decoder_input = Input(shape=(MAX_TOKENS), name='decoder_input')\n",
    "\n",
    "decoder_embedding = embedding_layer(decoder_input)\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, name='decoder_lstm')\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding,\n",
    "                                     initial_state=encoder_states)\n",
    "\n",
    "decoder_dense = Dense(vocab_size, activation='softmax', name='decoder_dense')\n",
    "decoder_output = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_input, decoder_input], decoder_output)\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-4d503384c8c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n\u001b[0m\u001b[0;32m      2\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m           epochs=EPOCHS)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit_generator(keras_dataset_generator(train_ds, epochs=5),\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[6., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define wiring of sampling models to get some faster inference\n",
    "\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    enc_input_seq = encoder.encode(input_seq)\n",
    "    \n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Batch size is 1 this is why there is an extra sequence\n",
    "    target_seq = np.zeros((1, 1, MAX_TOKENS))\n",
    "    \n",
    "    # sampling recurrent loop\n",
    "\n",
    "    i = 0\n",
    "    target_seq[0, 0, i] = encoder.encode(BOS)\n",
    "    decoded_sentence = ''\n",
    "    while True:\n",
    "        i += 1\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # argmax the output to get next token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word = encoder.decode[sampled_token_index]\n",
    "\n",
    "        decoded_sentence += sampled_word\n",
    "\n",
    "        # if max length or EOS, stop\n",
    "        if (sampled_char == EOS or\n",
    "           len(decoded_sentence) > MAX_TOKENS):\n",
    "            break\n",
    "\n",
    "        # update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, i] = sampled_token_index\n",
    "\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize some results from test data\n",
    "\n",
    "test_data = ['Whatsup bot?', 'marios is good', 'can i get admin pretty pls']\n",
    "\n",
    "for raw_text in test_data:\n",
    "    input_text = raw_text_preprocess(raw_text)\n",
    "\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_text)\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep learning\n",
    "encoder_model.save('encoder_model', save_format='tf')\n",
    "decoder_model.save('encoder_model', save_format='tf')\n",
    "\n",
    "# vocabulary maps\n",
    "encoder.save_to_file('text.encoder')"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
