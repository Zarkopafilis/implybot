{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import string\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import fasttext as ft\n",
    "import fasttext.util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "([PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')], True)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU'), tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>chat</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>Nigger in the house</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>Nigger</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>\"Yes\"</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>I have a hard on right now</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>same tbh</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>im actually jerking off rn</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>I'm fapping to cosplaying kids</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>same</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>con season is best season</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>true</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                             chat\n0             Nigger in the house\n1                          Nigger\n2                           \"Yes\"\n3      I have a hard on right now\n4                        same tbh\n5      im actually jerking off rn\n6  I'm fapping to cosplaying kids\n7                            same\n8       con season is best season\n9                            true"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our dataset is around ~15mb\n",
    "df = pd.read_csv('old_general.csv', header=None, usecols=[2], names=['chat'])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>chat</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>nigger in the house</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>nigger</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>i have a hard on right now</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>same tbh</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>im actually jerking off rn</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>im fapping to cosplaying kids</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>same</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>con season is best season</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>true</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                            chat\n0            nigger in the house\n1                         nigger\n2                            yes\n3     i have a hard on right now\n4                       same tbh\n5     im actually jerking off rn\n6  im fapping to cosplaying kids\n7                           same\n8      con season is best season\n9                           true"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['chat'] = df['chat'].apply(lambda x: x.lower())\n",
    "df['chat'] = df['chat'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
    "\n",
    "BOS = 'xxbos'\n",
    "EOS = 'xxeos'\n",
    "UNK = 'xxunk'\n",
    "\n",
    "def add_utility_tokens(r):\n",
    "    content = r['chat']\n",
    "\n",
    "    return f'{BOS} {content} {EOS}'\n",
    "\n",
    "df['chat'] = df.map(add_utility_tokens, axis=1)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{70: 7.0, 80: 9.0, 90: 12.0, 95: 16.0, 97: 19.0, 99: 28.0}"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tkn_len'] = df['chat'].apply(lambda x: len(x.split(' ')))\n",
    "\n",
    "_p = {i: np.percentile([l for l in df['tkn_len'].values], i) for i in [70, 80, 90, 95, 97, 99]}\n",
    "\n",
    "_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>chat</th>\n      <th>tkn_len</th>\n      <th>chat_2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>xxbos nigger in the house xxeos xxpad xxpad xx...</td>\n      <td>4</td>\n      <td>xxbos nigger in the house xxeos xxpad xxpad xx...</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>xxbos nigger xxeos xxpad xxpad xxpad xxpad xxp...</td>\n      <td>1</td>\n      <td>xxbos nigger xxeos xxpad xxpad xxpad xxpad xxp...</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>xxbos yes xxeos xxpad xxpad xxpad xxpad xxpad ...</td>\n      <td>1</td>\n      <td>xxbos yes xxeos xxpad xxpad xxpad xxpad xxpad ...</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>xxbos i have a hard on right now xxeos xxpad x...</td>\n      <td>7</td>\n      <td>xxbos i have a hard on right now xxeos xxpad x...</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>xxbos same tbh xxeos xxpad xxpad xxpad xxpad x...</td>\n      <td>2</td>\n      <td>xxbos same tbh xxeos xxpad xxpad xxpad xxpad x...</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>xxbos im actually jerking off rn xxeos xxpad x...</td>\n      <td>5</td>\n      <td>xxbos im actually jerking off rn xxeos xxpad x...</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>xxbos im fapping to cosplaying kids xxeos xxpa...</td>\n      <td>5</td>\n      <td>xxbos im fapping to cosplaying kids xxeos xxpa...</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>xxbos same xxeos xxpad xxpad xxpad xxpad xxpad...</td>\n      <td>1</td>\n      <td>xxbos same xxeos xxpad xxpad xxpad xxpad xxpad...</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>xxbos con season is best season xxeos xxpad xx...</td>\n      <td>5</td>\n      <td>xxbos con season is best season xxeos xxpad xx...</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>xxbos true xxeos xxpad xxpad xxpad xxpad xxpad...</td>\n      <td>1</td>\n      <td>xxbos true xxeos xxpad xxpad xxpad xxpad xxpad...</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                                chat  tkn_len  \\\n0  xxbos nigger in the house xxeos xxpad xxpad xx...        4   \n1  xxbos nigger xxeos xxpad xxpad xxpad xxpad xxp...        1   \n2  xxbos yes xxeos xxpad xxpad xxpad xxpad xxpad ...        1   \n3  xxbos i have a hard on right now xxeos xxpad x...        7   \n4  xxbos same tbh xxeos xxpad xxpad xxpad xxpad x...        2   \n5  xxbos im actually jerking off rn xxeos xxpad x...        5   \n6  xxbos im fapping to cosplaying kids xxeos xxpa...        5   \n7  xxbos same xxeos xxpad xxpad xxpad xxpad xxpad...        1   \n8  xxbos con season is best season xxeos xxpad xx...        5   \n9  xxbos true xxeos xxpad xxpad xxpad xxpad xxpad...        1   \n\n                                              chat_2  \n0  xxbos nigger in the house xxeos xxpad xxpad xx...  \n1  xxbos nigger xxeos xxpad xxpad xxpad xxpad xxp...  \n2  xxbos yes xxeos xxpad xxpad xxpad xxpad xxpad ...  \n3  xxbos i have a hard on right now xxeos xxpad x...  \n4  xxbos same tbh xxeos xxpad xxpad xxpad xxpad x...  \n5  xxbos im actually jerking off rn xxeos xxpad x...  \n6  xxbos im fapping to cosplaying kids xxeos xxpa...  \n7  xxbos same xxeos xxpad xxpad xxpad xxpad xxpad...  \n8  xxbos con season is best season xxeos xxpad xx...  \n9  xxbos true xxeos xxpad xxpad xxpad xxpad xxpad...  "
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_TOKENS = 20\n",
    "\n",
    "df = df[df['tkn_len'] <= MAX_TOKENS]\n",
    "\n",
    "def add_utility_tokens(r):\n",
    "    content = r['chat']\n",
    "\n",
    "    return f'{BOS} {content} {EOS}'\n",
    "\n",
    "df['chat'] = df.map(add_utility_tokens, axis=1)\n",
    "\n",
    "MAX_TOKENS += 2\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# push to tensorflow\n",
    "df['chat_shift'] = df['chat'].shift(-1)\n",
    "df.drop(df.tail(1).index, inplace=True) # drop last row for NaN due to shift\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((df['chat'].values, df['chat_shift'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "43604"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize and build vocab\n",
    "tokenizer = tfds.features.text.Tokenizer()\n",
    "\n",
    "vocabulary_set = set()\n",
    "vocabulary_set.update([BOS, EOS, UNK])\n",
    "\n",
    "for xb, yb in dataset:\n",
    "  xb_tokens = tokenizer.tokenize(xb.numpy())\n",
    "  vocabulary_set.update(xb_tokens)\n",
    "\n",
    "  yb_tokens = tokenizer.tokenize(yb.numpy())\n",
    "  vocabulary_set.update(yb_tokens)\n",
    "\n",
    "vocab_size = len(vocabulary_set)\n",
    "vocab_size += 1 # for padding introduced dataset.padded_batch (as 0.0f)\n",
    "\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collate_fn (for the fastai users)\n",
    "def encode(xb, yb):\n",
    "  enc_x, enc_y = encoder.encode(xb.numpy()), encoder.encode(yb)\n",
    "  return enc_x, enc_y\n",
    "\n",
    "def encode_map_fn(xb, yb):\n",
    "  enc_xb, enc_yb = tf.py_function(encode, \n",
    "                                       inp=[xb, yb], \n",
    "                                       Tout=(tf.int64, tf.int64))\n",
    "  return enc_xb, enc_yb\n",
    "\n",
    "dataset = dataset.map(encode_map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now you can convert each X-Y pair to\n",
    "# X-Y[:i]-Y triplets, for i in range(2, len(Y))\n",
    "# (enc-input, dec-input, dec-output)\n",
    "\n",
    "# note: if you want to use teacher forcing, you must implement your own \n",
    "# training loop: https://keras.io/guides/writing_a_training_loop_from_scratch/\n",
    "\n",
    "# we just do the first thing for simplicity\n",
    "def unwrap_for_seq2sec(xb, yb):        \n",
    "  return np.array([(xb, yb[1:i], yb)  for i in range(1, len(yb))])\n",
    "\n",
    "dataset = dataset.map(map_func=lambda xb, yb: tf.py_func(\n",
    "  func=unwrap_for_seq2sec, inp=[xb, yb], Tout=(tf.int64, tf.int64, tf.int64)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAKE_SIZE = 20 # just to visualize some in the end\n",
    "BUFFER_SIZE = 1024\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 15\n",
    "\n",
    "train_data = encoded_dataset.skip(TAKE_SIZE).shuffle(BUFFER_SIZE)\n",
    "train_data = train_data.padded_batch(BATCH_SIZE)\n",
    "\n",
    "test_data = encoded_dataset.take(TAKE_SIZE)\n",
    "test_data = test_data.padded_batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load fasttext model and build embeddings layer\n",
    "# ft.util.download_model('en', if_exists='ignore')\n",
    "en_vecs = ft.load_model('./cc.en.300.bin')\n",
    "en_vecs.get_dimension() # 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, 300))\n",
    "\n",
    "for word in vocabulary_set:\n",
    "    i = encoder.encode(word)\n",
    "    embedding_matrix[i] = en_vecs.get_word_vector(word)\n",
    "\n",
    "embedding_layer = tf.keras.layers.Embedding(vocab_size, 300, weights=[embedding_matrix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://keras.io/examples/lstm_seq2seq/\n",
    "\n",
    "latent_dim = 256\n",
    "\n",
    "# input is (tokens, vocab size)\n",
    "encoder_input = Input(shape=(None, MAX_TOKENS, vocab_size))\n",
    "\n",
    "# embedding dim is 300 from the fasttext model\n",
    "encoder_embedding = embedding_layer(encoder_input)\n",
    "\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_embedding)\n",
    "\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# same logic as model_input\n",
    "decoder_input = Input(shape=(None, MAX_TOKENS, vocab_size))\n",
    "\n",
    "decoder_embedding = decoder_input\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding,\n",
    "                                     initial_state=encoder_states)\n",
    "\n",
    "decoder_dense = Dense(vocab_size * MAX_TOKENS, activation='softmax')\n",
    "decoder_output = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_input, decoder_input], decoder_output)\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build dataset records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-4d503384c8c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n\u001b[0m\u001b[0;32m      2\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m           epochs=EPOCHS)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize some results from test data\n",
    "\n",
    "# for inference just:\n",
    "# 1. ensure input has got maximum MAX_TOKENS length\n",
    "# 2. create a tensor of length MAX_TOKENS\n",
    "# 3. paste the encoding tokens on the beginning of the tensor\n",
    "# 4. until the EOS token is encountered on the output or when length = MAX_TOKENS\n",
    "# 5. get the results of the output and plug it in the input to get next decoder input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('for_inference', save_format='tf')\n",
    "encoder.save_to_file('text.encoder')"
   ]
  }
 ]
}