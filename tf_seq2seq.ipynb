{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import string\n",
    "import math\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import fasttext as ft\n",
    "import fasttext.util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')], True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU'), tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Nigger in the house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Nigger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>\"Yes\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>I have a hard on right now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>same tbh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>im actually jerking off rn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>I'm fapping to cosplaying kids</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>con season is best season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             chat\n",
       "0             Nigger in the house\n",
       "1                          Nigger\n",
       "2                           \"Yes\"\n",
       "3      I have a hard on right now\n",
       "4                        same tbh\n",
       "5      im actually jerking off rn\n",
       "6  I'm fapping to cosplaying kids\n",
       "7                            same\n",
       "8       con season is best season\n",
       "9                            true"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our dataset is around ~15mb\n",
    "df = pd.read_csv('old_general.csv', header=None, usecols=[2], names=['chat'])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>nigger in the house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>nigger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>i have a hard on right now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>same tbh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>im actually jerking off rn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>im fapping to cosplaying kids</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>con season is best season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            chat\n",
       "0            nigger in the house\n",
       "1                         nigger\n",
       "2                            yes\n",
       "3     i have a hard on right now\n",
       "4                       same tbh\n",
       "5     im actually jerking off rn\n",
       "6  im fapping to cosplaying kids\n",
       "7                           same\n",
       "8      con season is best season\n",
       "9                           true"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UNK = 'xxunk'\n",
    "# OOV included in encoder\n",
    "\n",
    "def raw_text_preprocess(x):\n",
    "    return x.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "df['chat'] = df['chat'].apply(raw_text_preprocess)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{70: 7.0, 80: 9.0, 90: 12.0, 95: 16.0, 97: 19.0, 99: 28.0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tkn_len'] = df['chat'].apply(lambda x: len(x.split(' ')))\n",
    "\n",
    "_p = {i: np.percentile([l for l in df['tkn_len'].values], i) for i in [70, 80, 90, 95, 97, 99]}\n",
    "\n",
    "_p # {70: 7.0, 80: 9.0, 90: 12.0, 95: 16.0, 97: 19.0, 99: 28.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chat</th>\n",
       "      <th>tkn_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>xxbos nigger in the house xxeos</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>xxbos nigger xxeos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>xxbos yes xxeos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>xxbos i have a hard on right now xxeos</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>xxbos same tbh xxeos</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>xxbos im actually jerking off rn xxeos</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>xxbos im fapping to cosplaying kids xxeos</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>xxbos same xxeos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>xxbos con season is best season xxeos</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>xxbos true xxeos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        chat  tkn_len\n",
       "0            xxbos nigger in the house xxeos        4\n",
       "1                         xxbos nigger xxeos        1\n",
       "2                            xxbos yes xxeos        1\n",
       "3     xxbos i have a hard on right now xxeos        7\n",
       "4                       xxbos same tbh xxeos        2\n",
       "5     xxbos im actually jerking off rn xxeos        5\n",
       "6  xxbos im fapping to cosplaying kids xxeos        5\n",
       "7                           xxbos same xxeos        1\n",
       "8      xxbos con season is best season xxeos        5\n",
       "9                           xxbos true xxeos        1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_TOKENS = 20\n",
    "\n",
    "BOS = 'xxbos'\n",
    "EOS = 'xxeos'\n",
    "\n",
    "def add_utility_tokens(r):\n",
    "    content = r['chat']\n",
    "\n",
    "    return f'{BOS} {content} {EOS}'\n",
    "\n",
    "df['chat'] = df.apply(add_utility_tokens, axis=1)\n",
    "\n",
    "MAX_TOKENS += 2\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['chat_shift'] = df['chat'].shift(-1)\n",
    "df.drop(df.tail(1).index, inplace=True) # drop last row for NaN due to shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebce3359bb2b4656b2a83933f0f9ac67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=183090.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19922"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize and build vocab\n",
    "tokenizer = tfds.features.text.Tokenizer()\n",
    "\n",
    "OCCURENCES_TRESHOLD = 2\n",
    "\n",
    "vocab_counter = Counter()\n",
    "\n",
    "vocab_counter.update([BOS, EOS, UNK] * OCCURENCES_TRESHOLD)\n",
    "\n",
    "for _, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "  xb = row['chat']\n",
    "  xb_tokens = tokenizer.tokenize(xb)\n",
    "  vocab_counter.update(xb_tokens)\n",
    "\n",
    "# keep only words that appear more than OCCURENCES_TRESHOLD\n",
    "vocabulary_set = set(el for el in vocab_counter.elements() if vocab_counter[el] >= OCCURENCES_TRESHOLD)\n",
    "\n",
    "vocabulary_set.update([BOS, EOS, UNK])\n",
    "   \n",
    "vocab_size = len(vocabulary_set)\n",
    "\n",
    "encoder = tfds.features.text.TokenTextEncoder(vocabulary_set, oov_token=UNK, lowercase=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('backtrack riding silver reeeeeeeeeeeeeeeeeeee backtrack xxunk',\n",
       " 'xxunk xxunk')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.decode([0, 1, 2, 3, vocab_size, vocab_size+1]), encoder.decode([vocab_size+2, vocab_size+3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load fasttext model and build embeddings layer\n",
    "# ft.util.download_model('en', if_exists='ignore')\n",
    "en_vecs = ft.load_model('./cc.en.300.bin')\n",
    "en_vecs.get_dimension() # 300\n",
    "\n",
    "# Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
    "# you can safely ignore this warning, it's for other model types and (possibly) deprecation warning for other versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19924"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = encoder.vocab_size # compensate for the 0 paddings\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size, 300))\n",
    "\n",
    "for word in vocabulary_set:\n",
    "    i = encoder.encode(word)\n",
    "    embedding_matrix[i] = en_vecs.get_word_vector(word)\n",
    "    \n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# release 8gb of memory by unloading the fasttext model\n",
    "del en_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODER_INPUT_NAME = 'encoder_input'\n",
    "DECODER_INPUT_NAME = 'decoder_input'\n",
    "DECODER_OUTPUT_NAME = 'decoder_output'\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# What if I don't want to use teacher forcing for training?\n",
    "# > Custom training loop, look below:\n",
    "# https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html\n",
    "\n",
    "# you could make this lazy-generator wise too\n",
    "#for _, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "def keras_data_generator(dataframe):\n",
    "    while True:\n",
    "        for _, row in dataframe.iterrows():\n",
    "            ch = row['chat']\n",
    "            ch_shift = row['chat_shift']\n",
    "            \n",
    "            # print(f'{ch} - {ch_shift}')\n",
    "\n",
    "            xb, yb = encoder.encode(ch), encoder.encode(ch_shift)\n",
    "            if len(xb) >= MAX_TOKENS or len(yb) >= MAX_TOKENS:\n",
    "                continue\n",
    "\n",
    "            xb_padded = pad_sequences([xb], MAX_TOKENS, padding='post')\n",
    "\n",
    "            # [enc_input, dec_input], dec_output\n",
    "            for i in range(1, len(yb)-1):\n",
    "                dec_in = pad_sequences([yb[0:i]], MAX_TOKENS, padding='post')\n",
    "                dec_out = pad_sequences([yb[0:i+1]], MAX_TOKENS, padding='post')\n",
    "                \n",
    "                # yields\n",
    "                yield {ENCODER_INPUT_NAME: xb_padded, DECODER_INPUT_NAME: dec_in}, {DECODER_OUTPUT_NAME: dec_out}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'encoder_input': array([[13528,  9508, 13414, 10216,   168, 15301,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0]]),\n",
       "  'decoder_input': array([[13528,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0]])},\n",
       " {'decoder_output': array([[13528,  9508,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0]])})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(keras_data_generator(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, 22)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input (InputLayer)      [(None, 22)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_embedding (Embedding)   (None, 22, 300)      5977200     encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_embedding (Embedding)   (None, 22, 300)      5977200     decoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "encoder_lstm (LSTM)             [(None, 128), (None, 219648      encoder_embedding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)             (None, 22, 128)      219648      decoder_embedding[0][0]          \n",
      "                                                                 encoder_lstm[0][1]               \n",
      "                                                                 encoder_lstm[0][2]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output (Dense)          (None, 22, 19924)    2570196     decoder_lstm[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 14,963,892\n",
      "Trainable params: 14,963,892\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Reshape\n",
    "\n",
    "# https://keras.io/examples/lstm_seq2seq/\n",
    "\n",
    "# this one messes with layer names and appends :X numbers\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "latent_dim = 128\n",
    "\n",
    "input_tensor_type = tf.int64\n",
    "\n",
    "encoder_embedding = tf.keras.layers.Embedding(vocab_size, 300, weights=[embedding_matrix], name='encoder_embedding')\n",
    "decoder_embedding = tf.keras.layers.Embedding(vocab_size, 300, weights=[embedding_matrix], name='decoder_embedding')\n",
    "\n",
    "# input is (tokens, vocab size)\n",
    "encoder_input = Input(shape=(MAX_TOKENS,), dtype=input_tensor_type, name=ENCODER_INPUT_NAME)\n",
    "\n",
    "# embedding dim is 300 from the fasttext model\n",
    "encoder_embedding = encoder_embedding(encoder_input) # None, MAX_TOKENS, 300\n",
    "\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True, name='encoder_lstm')\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# # same logic as model_input\n",
    "decoder_input = Input(shape=(MAX_TOKENS,), dtype=input_tensor_type, name=DECODER_INPUT_NAME)\n",
    "decoder_embedding = decoder_embedding(decoder_input)\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, name='decoder_lstm')(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_output = Dense(vocab_size, activation='softmax', name=DECODER_OUTPUT_NAME)(decoder_lstm)\n",
    "\n",
    "model = Model([encoder_input, decoder_input], decoder_output)\n",
    "\n",
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1062410"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate how much unwrapping will the generator do\n",
    "expanded_samples = 1062410\n",
    "# expanded_samples = 0\n",
    "\n",
    "# for _, row in df.iterrows():\n",
    "#     ch = row['chat_shift']\n",
    "#     e = encoder.encode(ch)\n",
    "#     # print(e)\n",
    "#     expanded_samples += len(e) - 2 # 1 for BOS, 1 for last token (EOS)\n",
    "    \n",
    "expanded_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos nigger in the house xxeos - xxbos nigger xxeos\n",
      "Epoch 1/5\n",
      "xxbos nigger xxeos - xxbos yes xxeos\n",
      "    1/16600 [..............................] - ETA: 0s - loss: 0.3307 - accuracy: 0.9545xxbos yes xxeos - xxbos i have a hard on right now xxeos\n",
      "    8/16600 [..............................] - ETA: 30:57 - loss: 0.6394 - accuracy: 0.8977xxbos i have a hard on right now xxeos - xxbos same tbh xxeos\n",
      "   10/16600 [..............................] - ETA: 33:38 - loss: 0.7246 - accuracy: 0.8864xxbos same tbh xxeos - xxbos im actually jerking off rn xxeos\n",
      "   15/16600 [..............................] - ETA: 35:30 - loss: 0.7139 - accuracy: 0.8879xxbos im actually jerking off rn xxeos - xxbos im fapping to cosplaying kids xxeos\n",
      "   20/16600 [..............................] - ETA: 35:24 - loss: 0.7244 - accuracy: 0.8818xxbos im fapping to cosplaying kids xxeos - xxbos same xxeos\n",
      "   21/16600 [..............................] - ETA: 35:19 - loss: 0.7485 - accuracy: 0.8766xxbos same xxeos - xxbos con season is best season xxeos\n",
      "   26/16600 [..............................] - ETA: 35:17 - loss: 0.7239 - accuracy: 0.8811xxbos con season is best season xxeos - xxbos true xxeos\n",
      "   27/16600 [..............................] - ETA: 35:14 - loss: 0.7476 - accuracy: 0.8771xxbos true xxeos - xxbos how tight is hillary clintons vagina xxeos\n",
      "   33/16600 [..............................] - ETA: 35:09 - loss: 0.7416 - accuracy: 0.8774xxbos how tight is hillary clintons vagina xxeos - xxbos probably not very tight xxeos\n",
      "   37/16600 [..............................] - ETA: 35:01 - loss: 0.7494 - accuracy: 0.8759xxbos probably not very tight xxeos - xxbos she hides her emails in there xxeos\n",
      "   43/16600 [..............................] - ETA: 34:57 - loss: 0.7693 - accuracy: 0.8732xxbos she hides her emails in there xxeos - xxbos hello niggers xxeos\n",
      "   45/16600 [..............................] - ETA: 34:55 - loss: 0.7795 - accuracy: 0.8717xxbos hello niggers xxeos - xxbos hello xxeos\n",
      "   46/16600 [..............................] - ETA: 34:53 - loss: 0.7757 - accuracy: 0.8725xxbos hello xxeos - xxbos fellow nigger xxeos\n",
      "   48/16600 [..............................] - ETA: 34:50 - loss: 0.7564 - accuracy: 0.8759xxbos fellow nigger xxeos - xxbos does sound work is anyone using it xxeos\n",
      "   55/16600 [..............................] - ETA: 34:50 - loss: 0.7702 - accuracy: 0.8727xxbos does sound work is anyone using it xxeos - xxbos sound works good but im not using it xxeos\n",
      "   63/16600 [..............................] - ETA: 34:56 - loss: 0.7968 - accuracy: 0.8636xxbos sound works good but im not using it xxeos - xxbos because im cleaning up my tv stand xxeos\n",
      "   70/16600 [..............................] - ETA: 34:52 - loss: 0.8054 - accuracy: 0.8584xxbos because im cleaning up my tv stand xxeos - xxbos as its shitty xxeos\n",
      "   73/16600 [..............................] - ETA: 34:48 - loss: 0.8072 - accuracy: 0.8580xxbos as its shitty xxeos - xxbos sup nignog xxeos\n",
      "   75/16600 [..............................] - ETA: 34:51 - loss: 0.8021 - accuracy: 0.8594xxbos sup nignog xxeos - xxbos oh i see xxeos\n",
      "   78/16600 [..............................] - ETA: 34:54 - loss: 0.7908 - accuracy: 0.8619xxbos oh i see xxeos - xxbos sup xxeos\n",
      "   79/16600 [..............................] - ETA: 34:54 - loss: 0.7903 - accuracy: 0.8619xxbos sup xxeos - xxbos whats this xxeos\n",
      "   81/16600 [..............................] - ETA: 34:53 - loss: 0.7786 - accuracy: 0.8642xxbos whats this xxeos - xxbos a place to shitpost xxeos\n",
      "   85/16600 [..............................] - ETA: 34:51 - loss: 0.7653 - accuracy: 0.8663xxbos a place to shitpost xxeos - xxbos and jerk off to cartoon horses xxeos\n",
      "   91/16600 [..............................] - ETA: 34:57 - loss: 0.7678 - accuracy: 0.8656xxbos and jerk off to cartoon horses xxeos - xxbos ccan i jerkoff to futas  xxeos\n",
      "   96/16600 [..............................] - ETA: 35:04 - loss: 0.7664 - accuracy: 0.8651xxbos ccan i jerkoff to futas  xxeos - xxbos this is a libertarian masturbation area xxeos\n",
      "  102/16600 [..............................] - ETA: 35:03 - loss: 0.7646 - accuracy: 0.8641xxbos this is a libertarian masturbation area xxeos - xxbos all lewds welcome xxeos\n",
      "  105/16600 [..............................] - ETA: 35:11 - loss: 0.7659 - accuracy: 0.8641xxbos all lewds welcome xxeos - xxbos good xxeos\n",
      "  106/16600 [..............................] - ETA: 35:12 - loss: 0.7675 - accuracy: 0.8641xxbos good xxeos - xxbos i want a black nissan maxima xxeos\n",
      "  112/16600 [..............................] - ETA: 35:16 - loss: 0.7545 - accuracy: 0.8665xxbos i want a black nissan maxima xxeos - xxbos nigsan xxeos\n",
      "  113/16600 [..............................] - ETA: 35:22 - loss: 0.7600 - accuracy: 0.8656xxbos nigsan xxeos - xxbos yes xxeos\n",
      "  114/16600 [..............................] - ETA: 35:23 - loss: 0.7562 - accuracy: 0.8664xxbos yes xxeos - xxbos nigsan maxidicksizema xxeos\n",
      "  116/16600 [..............................] - ETA: 35:24 - loss: 0.7487 - accuracy: 0.8679xxbos nigsan maxidicksizema xxeos - xxbos ayy lmao xxeos\n",
      "  118/16600 [..............................] - ETA: 35:28 - loss: 0.7430 - accuracy: 0.8690xxbos ayy lmao xxeos - xxbos good lord im the only one still here xxeos\n",
      "  124/16600 [..............................] - ETA: 35:38 - loss: 0.7383 - accuracy: 0.8691"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-101-481a083c7b64>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras_data_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexpanded_samples\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    609\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1665\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1667\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1746\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "model.fit(keras_data_generator(df), epochs=5, steps_per_epoch=expanded_samples//BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13528, 5045, 5497, 19923, 19816, 15094, 15301]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xxbos ccan i jerkoff to futas  xxeos\n",
    "encoder.encode('xxbos ccan i jerkofff to futas  xxeos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[6., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define wiring of sampling models to get some faster inference\n",
    "\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    enc_input_seq = encoder.encode(input_seq)\n",
    "    \n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Batch size is 1 this is why there is an extra sequence\n",
    "    target_seq = np.zeros((1, 1, MAX_TOKENS))\n",
    "    \n",
    "    # sampling recurrent loop\n",
    "\n",
    "    i = 0\n",
    "    target_seq[0, 0, i] = encoder.encode(BOS)\n",
    "    decoded_sentence = ''\n",
    "    while True:\n",
    "        i += 1\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # argmax the output to get next token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word = encoder.decode[sampled_token_index]\n",
    "\n",
    "        decoded_sentence += sampled_word\n",
    "\n",
    "        # if max length or EOS, stop\n",
    "        if (sampled_char == EOS or\n",
    "           len(decoded_sentence) > MAX_TOKENS):\n",
    "            break\n",
    "\n",
    "        # update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, i] = sampled_token_index\n",
    "\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize some results from test data\n",
    "\n",
    "test_data = ['Whatsup bot?', 'marios is good', 'can i get admin pretty pls']\n",
    "\n",
    "for raw_text in test_data:\n",
    "    input_text = raw_text_preprocess(raw_text)\n",
    "\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_text)\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep learning\n",
    "encoder_model.save('encoder_model', save_format='tf')\n",
    "decoder_model.save('encoder_model', save_format='tf')\n",
    "\n",
    "# vocabulary maps\n",
    "encoder.save_to_file('text.encoder')"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
